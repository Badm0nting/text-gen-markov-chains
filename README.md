# ðŸ“š Text Generation with Markov Chains

This project demonstrates how to generate text using **Markov chains** trained on classical literature. It uses **NLTK** to access the Gutenberg corpus, **spaCy** for parsing and NLP, and **Markovify** to generate new text based on learned statistical models.

---

## ðŸŽ¯ Objective

Implement a simple text generation algorithm using Markov chains.  
This involves creating a statistical model that predicts the probability of a word based on one or more preceding words.

---

## ðŸ§° Tech Stack

- **Python 3**
- **Google Colab** (Jupyter Notebook Environment)
- `nltk` for corpus and tokenization
- `spacy` for NLP pipeline
- `markovify` for Markov model text generation

---

## ðŸ“‚ Dataset

The project uses texts from the **Gutenberg corpus** provided by NLTK:
- *Hamlet*
- *Macbeth*
- *Julius Caesar*  
(All texts by William Shakespeare)

---
## âœ… Sample Output

To-morrow is with me.
Come, come, give me up.
Let me be your humble servant.
Hark! who comes here?
We will leave you then.

---

## ðŸ“„ License

This project uses public domain literary works from Project Gutenberg.
For educational and non-commercial use.
